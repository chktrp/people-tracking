{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "People Trajectory Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05JPP7WPMmyJ",
        "colab_type": "text"
      },
      "source": [
        "## Collect video sample from internet\n",
        "\n",
        "video source: \n",
        "\n",
        "- Free City Street Footage - Royalty Free Stock Footage - People Walking Stock Footage No Copyright\n",
        "\n",
        "  https://www.youtube.com/watch?v=bwJ-TNu0hGM\n",
        "\n",
        "\n",
        "tools: \n",
        "- Video Downloader\n",
        "\n",
        "  https://x2convert.com/\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns0-mVHKNxSB",
        "colab_type": "text"
      },
      "source": [
        "## Read video frames\n",
        "\n",
        "https://theailearner.com/2018/10/15/extracting-and-saving-video-frames-using-opencv-python/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HrIdq1SPyNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV7u5ldpgpwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUHTKqa1NhVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "video_file_path = './city.mp4'\n",
        "frames = []\n",
        "\n",
        "cap= cv2.VideoCapture(video_file_path)\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "    if ret == False:\n",
        "        break\n",
        "    frames.append(frame)\n",
        "cap.release()\n",
        "\n",
        "frames = np.array(frames)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYUrJPJbPrhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frames.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz_GjHM4PtSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv2_imshow(frames[0,:,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHa21epUSY9j",
        "colab_type": "text"
      },
      "source": [
        "## Object Detection\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSsElMlTSX93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\n",
        "!tar -xvf ./ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vru05mDomUVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "model_path = '/content/ssd_mobilenet_v2_320x320_coco17_tpu-8/saved_model'\n",
        "\n",
        "start_time = time.time()\n",
        "tf.keras.backend.clear_session()\n",
        "detect_fn = tf.saved_model.load(model_path)\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Elapsed time: ' + str(elapsed_time) + 's')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzcr3Lt1lpCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "process_size = 360\n",
        "score_threshold = 0.6\n",
        "\n",
        "process_num = frames.shape[0]\n",
        "\n",
        "if process_num > 2000:\n",
        "  process_num = 2000\n",
        "\n",
        "conseq_bbs = []\n",
        "min_size = {\n",
        "    'width': 0.01,\n",
        "    'height': 0.02\n",
        "}\n",
        "\n",
        "for i in range(process_num):\n",
        "  frame = frames[i,:,:,:3]\n",
        "  original_size = frame.shape\n",
        "  frame_height, frame_width = original_size[:2]\n",
        "\n",
        "  cur_frame = cv2.resize(frame,(process_size, process_size))\n",
        "\n",
        "  input_image = cur_frame.reshape(1, cur_frame.shape[0], cur_frame.shape[1], 3)\n",
        "\n",
        "  detections = detect_fn(input_image)\n",
        "\n",
        "  num_detections = int(detections['num_detections'].numpy())\n",
        "  obj_bbs = []\n",
        "  obj_ids = []\n",
        "  for j in range(num_detections):\n",
        "    class_id = int(detections['detection_classes'][0][j].numpy())\n",
        "    score = float(detections['detection_scores'][0][j].numpy())\n",
        "    bbox = [float(v) for v in detections['detection_boxes'][0][j].numpy()]\n",
        "\n",
        "    x = bbox[1] * frame_width\n",
        "    y_ = bbox[0] * frame_height\n",
        "    right = bbox[3] * frame_width\n",
        "    bottom = bbox[2] * frame_height\n",
        "\n",
        "    bbox = [x, y_, right, bottom]\n",
        "    obj_width = bbox[3]-bbox[1]\n",
        "    obj_height = bbox[2]-bbox[0]\n",
        "    if score > score_threshold and class_id == 1 and obj_width >= frame_width*min_size['width']:\n",
        "      obj_bbs.append(bbox)\n",
        "      obj_ids.append(class_id)\n",
        "\n",
        "  conseq_bbs.append(obj_bbs)\n",
        "\n",
        "  if i%100 == 0:\n",
        "    print(i, time.time())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypbYNFYzUebU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(conseq_bbs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJGevXsAsK-C",
        "colab_type": "text"
      },
      "source": [
        "## Draw Bounding Boxes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvK8i5yprhFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frame_idx = 0\n",
        "\n",
        "obj_bbs_tmp = conseq_bbs[frame_idx]\n",
        "\n",
        "frame_copy = frames[frame_idx, :,:,:].copy()\n",
        "frame_height, frame_width = original_size[:2]\n",
        "\n",
        "for i in range(len(obj_bbs_tmp)):\n",
        "\n",
        "  x = obj_bbs_tmp[i][1] * frame_width\n",
        "  y_ = obj_bbs_tmp[i][0] * frame_height\n",
        "  right = obj_bbs_tmp[i][3] * frame_width\n",
        "  bottom = obj_bbs_tmp[i][2] * frame_height\n",
        "  \n",
        "  cv2.rectangle(frame_copy, (int(x), int(y_)), (int(right), int(bottom)), (0,0,255), thickness=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fK2YgEMb2OUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if len(obj_bbs_tmp) > 0:\n",
        "  obj_bbs_tmp[frame_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEoIxKmq5OY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv2_imshow(frame_copy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evyy3nBk5y4c",
        "colab_type": "text"
      },
      "source": [
        "## Write video to a file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHPiRfqktKi9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# frame_height, frame_width = original_size[:2]\n",
        "# out = cv2.VideoWriter('output.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
        "\n",
        "# total_frame_number = len(conseq_bbs)\n",
        "# print('total frame number:', total_frame_number)\n",
        "\n",
        "# for idx in range(total_frame_number):\n",
        "#   frame_copy = frames[idx].copy()\n",
        "#   obj_bbs_tmp = conseq_bbs[idx]\n",
        "\n",
        "#   for i in range(len(obj_bbs_tmp)):\n",
        "\n",
        "#     x = obj_bbs_tmp[i][1] * frame_width\n",
        "#     y_ = obj_bbs_tmp[i][0] * frame_height\n",
        "#     right = obj_bbs_tmp[i][3] * frame_width\n",
        "#     bottom = obj_bbs_tmp[i][2] * frame_height\n",
        "\n",
        "#     obj_bbs_tmp[i] = [x, y_, right, bottom]\n",
        "    \n",
        "#     cv2.rectangle(frame_copy, (int(x), int(y_)), (int(right), int(bottom)), (0,0,255), thickness=2)\n",
        "#   out.write(frame_copy)\n",
        "# out.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whFpx5D4HHag",
        "colab_type": "text"
      },
      "source": [
        "## Object tracking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uISFDVXn6fm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://www.pyimagesearch.com/2018/07/23/simple-object-tracking-with-opencv/\n",
        "\n",
        "# import the necessary packages\n",
        "from scipy.spatial import distance as dist\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "class CentroidTracker():\n",
        "\tdef __init__(self, maxDisappeared=50, maxDistance=50):\n",
        "\t\t# initialize the next unique object ID along with two ordered\n",
        "\t\t# dictionaries used to keep track of mapping a given object\n",
        "\t\t# ID to its centroid and number of consecutive frames it has\n",
        "\t\t# been marked as \"disappeared\", respectively\n",
        "\t\tself.nextObjectID = 0\n",
        "\t\tself.objects = OrderedDict()\n",
        "\t\tself.boxes = OrderedDict()\n",
        "\t\tself.colors = OrderedDict()\n",
        "\t\tself.histories = OrderedDict()\n",
        "\t\tself.disappeared = OrderedDict()\n",
        "\t\n",
        "\t\tself.maxdist = maxDistance\n",
        "\n",
        "\t\t# store the number of maximum consecutive frames a given\n",
        "\t\t# object is allowed to be marked as \"disappeared\" until we\n",
        "\t\t# need to deregister the object from tracking\n",
        "\t\tself.maxDisappeared = maxDisappeared\n",
        "\n",
        "\tdef register(self, centroid, box):\n",
        "\t\t# when registering an object we use the next available object\n",
        "\t\t# ID to store the centroid\n",
        "\t\tself.objects[self.nextObjectID] = centroid\n",
        "\t\tself.boxes[self.nextObjectID] = box\n",
        "\t\tself.histories[self.nextObjectID] = [(int((box[0]+box[2])/2), int(box[3]))]\n",
        "\t\tself.disappeared[self.nextObjectID] = 0\n",
        "\t\tr = random.randint(0,255)\n",
        "\t\tself.colors[self.nextObjectID] = (r, \n",
        "\t\t                                \trandom.randint(0,255), \n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t255-r)\n",
        "\t\tself.nextObjectID += 1\n",
        "\n",
        "\tdef deregister(self, objectID):\n",
        "\t\t# to deregister an object ID we delete the object ID from\n",
        "\t\t# both of our respective dictionaries\n",
        "\t\tdel self.objects[objectID]\n",
        "\t\tdel self.boxes[objectID]\n",
        "\t\tdel self.disappeared[objectID]\n",
        "\t\t# keep histories\n",
        "\t\t# del self.histories[objectID]\n",
        "\t\tdel self.colors[objectID]\n",
        "\n",
        "\tdef update(self, rects):\n",
        "\t\t# check to see if the list of input bounding box rectangles\n",
        "\t\t# is empty\n",
        "\t\tif len(rects) == 0:\n",
        "\t\t\t# loop over any existing tracked objects and mark them\n",
        "\t\t\t# as disappeared\n",
        "\t\t\tderegister_list = []\n",
        "\t\t\tfor objectID in self.disappeared.keys():\n",
        "\t\t\t\tself.disappeared[objectID] += 1\n",
        "\n",
        "\t\t\t\t# if we have reached a maximum number of consecutive\n",
        "\t\t\t\t# frames where a given object has been marked as\n",
        "\t\t\t\t# missing, deregister it\n",
        "\t\t\t\tif self.disappeared[objectID] > self.maxDisappeared:\n",
        "\t\t\t\t\tderegister_list.append(objectID)\n",
        "\n",
        "\t\t\tif len(deregister_list) > 0:\n",
        "\t\t\t\tfor obj_id in deregister_list:\n",
        "\t\t\t\t\tself.deregister(obj_id)\n",
        "\n",
        "\t\t\t# return early as there are no centroids or tracking info\n",
        "\t\t\t# to update\n",
        "\t\t\treturn self.objects, self.boxes, self.colors, self.histories\n",
        "\n",
        "\t\t# initialize an array of input centroids for the current frame\n",
        "\t\tinputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
        "\t\tinputBoxes = np.zeros((len(rects), 4), dtype=\"int\")\n",
        "\n",
        "\t\t# loop over the bounding box rectangles\n",
        "\t\tfor (i, (startX, startY, endX, endY)) in enumerate(rects):\n",
        "\t\t\t# use the bounding box coordinates to derive the centroid\n",
        "\t\t\tcX = int((startX + endX) / 2.0)\n",
        "\t\t\tcY = int((startY + endY) / 2.0)\n",
        "\t\t\tinputCentroids[i] = (cX, cY)\n",
        "\t\t\tinputBoxes[i] = (startX, startY, endX, endY)\n",
        "\n",
        "\t\t# if we are currently not tracking any objects take the input\n",
        "\t\t# centroids and register each of them\n",
        "\t\tif len(self.objects) == 0:\n",
        "\t\t\tfor i in range(0, len(inputCentroids)):\n",
        "\t\t\t\tself.register(inputCentroids[i], inputBoxes[i])\n",
        "\n",
        "\t\t# otherwise, are are currently tracking objects so we need to\n",
        "\t\t# try to match the input centroids to existing object\n",
        "\t\t# centroids\n",
        "\t\telse:\n",
        "\t\t\t# grab the set of object IDs and corresponding centroids\n",
        "\t\t\tobjectIDs = list(self.objects.keys())\n",
        "\t\t\tobjectCentroids = list(self.objects.values())\n",
        "\t\t\t# objectBoxes = list(self.boxes.values())\n",
        "\n",
        "\t\t\t# compute the distance between each pair of object\n",
        "\t\t\t# centroids and input centroids, respectively -- our\n",
        "\t\t\t# goal will be to match an input centroid to an existing\n",
        "\t\t\t# object centroid\n",
        "\t\t\tD = dist.cdist(np.array(objectCentroids), inputCentroids)\n",
        "\n",
        "\t\t\t# in order to perform this matching we must (1) find the\n",
        "\t\t\t# smallest value in each row and then (2) sort the row\n",
        "\t\t\t# indexes based on their minimum values so that the row\n",
        "\t\t\t# with the smallest value as at the *front* of the index\n",
        "\t\t\t# list\n",
        "\t\t\trows = D.min(axis=1).argsort()\n",
        "\n",
        "\t\t\t# next, we perform a similar process on the columns by\n",
        "\t\t\t# finding the smallest value in each column and then\n",
        "\t\t\t# sorting using the previously computed row index list\n",
        "\t\t\tcols = D.argmin(axis=1)[rows]\n",
        "\n",
        "\t\t\t# in order to determine if we need to update, register,\n",
        "\t\t\t# or deregister an object we need to keep track of which\n",
        "\t\t\t# of the rows and column indexes we have already examined\n",
        "\t\t\tusedRows = set()\n",
        "\t\t\tusedCols = set()\n",
        "\n",
        "\t\t\t# loop over the combination of the (row, column) index\n",
        "\t\t\t# tuples\n",
        "\t\t\tfor (row, col) in zip(rows, cols):\n",
        "\t\t\t\t# if we have already examined either the row or\n",
        "\t\t\t\t# column value before, ignore it\n",
        "\t\t\t\t# val\n",
        "\t\t\t\tif row in usedRows or col in usedCols:\n",
        "\t\t\t\t\tcontinue\n",
        "\n",
        "\t\t\t\tif D[row, col] > self.maxdist:\n",
        "\t\t\t\t\tcontinue\n",
        "\n",
        "\t\t\t\t# otherwise, grab the object ID for the current row,\n",
        "\t\t\t\t# set its new centroid, and reset the disappeared\n",
        "\t\t\t\t# counter\n",
        "\t\t\t\tobjectID = objectIDs[row]\n",
        "\t\t\t\tself.objects[objectID] = inputCentroids[col]\n",
        "\t\t\t\tself.boxes[objectID] = inputBoxes[col]\n",
        "\t\t\t\tself.histories[objectID].append((int((inputBoxes[col][0]+inputBoxes[col][2])/2), int(inputBoxes[col][3])))\n",
        "\t\t\t\tself.disappeared[objectID] = 0\n",
        "\n",
        "\t\t\t\t# indicate that we have examined each of the row and\n",
        "\t\t\t\t# column indexes, respectively\n",
        "\t\t\t\tusedRows.add(row)\n",
        "\t\t\t\tusedCols.add(col)\n",
        "\n",
        "\t\t\t# compute both the row and column index we have NOT yet\n",
        "\t\t\t# examined\n",
        "\t\t\tunusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
        "\t\t\tunusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
        "\n",
        "\t\t\t# in the event that the number of object centroids is\n",
        "\t\t\t# equal or greater than the number of input centroids\n",
        "\t\t\t# we need to check and see if some of these objects have\n",
        "\t\t\t# potentially disappeared\n",
        "\t\t\tif D.shape[0] >= D.shape[1]:\n",
        "\t\t\t\t# loop over the unused row indexes\n",
        "\t\t\t\tfor row in unusedRows:\n",
        "\t\t\t\t\t# grab the object ID for the corresponding row\n",
        "\t\t\t\t\t# index and increment the disappeared counter\n",
        "\t\t\t\t\tobjectID = objectIDs[row]\n",
        "\t\t\t\t\tself.disappeared[objectID] += 1\n",
        "\n",
        "\t\t\t\t\t# check to see if the number of consecutive\n",
        "\t\t\t\t\t# frames the object has been marked \"disappeared\"\n",
        "\t\t\t\t\t# for warrants deregistering the object\n",
        "\t\t\t\t\tif self.disappeared[objectID] > self.maxDisappeared:\n",
        "\t\t\t\t\t\tself.deregister(objectID)\n",
        "\n",
        "\t\t\t# otherwise, if the number of input centroids is greater\n",
        "\t\t\t# than the number of existing object centroids we need to\n",
        "\t\t\t# register each new input centroid as a trackable object\n",
        "\t\t\telse:\n",
        "\t\t\t\tfor col in unusedCols:\n",
        "\t\t\t\t\tself.register(inputCentroids[col], inputBoxes[col])\n",
        "\n",
        "\t\t# return the set of trackable objects\n",
        "\t\treturn self.objects, self.boxes, self.colors, self.histories"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTglN7yqHBwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ct = CentroidTracker(maxDisappeared=10, maxDistance=20)\n",
        "\n",
        "frame_height, frame_width = original_size[:2]\n",
        "out = cv2.VideoWriter('output.mp4',cv2.VideoWriter_fourcc(*'MP4V'), 20, (frame_width,frame_height))\n",
        "\n",
        "total_frame_number = len(conseq_bbs)\n",
        "print('total frame number:', total_frame_number)\n",
        "\n",
        "for idx in range(total_frame_number):\n",
        "  frame_copy = frames[idx].copy()\n",
        "  rects = conseq_bbs[idx]\n",
        "  \n",
        "  (objects, boxes, colors, histories) = ct.update(rects)\n",
        "  # print(idx, rects)\n",
        "\n",
        "\t# loop over the tracked objects\n",
        "  for (i, (objectID, centroid)) in enumerate(objects.items()):\n",
        "\t\t# draw both the ID of the object and the centroid of the\n",
        "\t\t# object on the output frame\n",
        "    text = str(objectID)\n",
        "    cv2.putText(frame_copy, text, (centroid[0] - 10, centroid[1] - 10),\n",
        "      cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "    \n",
        "    x = boxes[objectID][0]\n",
        "    y_ = boxes[objectID][1]\n",
        "    right = boxes[objectID][2]\n",
        "    bottom = boxes[objectID][3]\n",
        "\n",
        "    cv2.rectangle(frame_copy, (int(x), int(y_)), (int(right), int(bottom)), colors[objectID], thickness=2)\n",
        "    \n",
        "  out.write(frame_copy)\n",
        "out.release()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KswXrWTW8f5D",
        "colab_type": "text"
      },
      "source": [
        "## Background estimation\n",
        "https://www.learnopencv.com/simple-background-estimation-in-videos-using-opencv-c-python/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5hbZKMg8fgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "background = np.median(frames[:], axis=0).astype(dtype=np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmFokzLgjKxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv2_imshow(background)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-R12C5WC8TXu",
        "colab_type": "text"
      },
      "source": [
        "## Trajectory history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2NM4ZZaoGQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "background_copy = background.copy()\n",
        "line_thickness = 5\n",
        "# line_thickness_max = 10\n",
        "min_history = 2\n",
        "history_list = []\n",
        "\n",
        "for key in histories.keys():\n",
        "  history = histories[key]\n",
        "  if len(history) > min_history:\n",
        "    for i in range(len(history)-1):\n",
        "      cv2.line(background_copy, (history[i][0], history[i][1]), (history[i+1][0], history[i+1][1]), (0, 0, 255), thickness=line_thickness)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VFtoFPRnv3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv2_imshow(background_copy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJQDt10IrMLH",
        "colab_type": "text"
      },
      "source": [
        "## Trajectory density"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgdY7gWK8ltY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('frame height:', frame_height, 'frame width:', frame_width)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3D9zgPsn2cm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_range = 17\n",
        "y_range = 9\n",
        "\n",
        "xedges = [i*40 for i in range(x_range)]\n",
        "yedges = [i*40 for i in range(y_range)]\n",
        "\n",
        "history_x = []\n",
        "history_y = []\n",
        "\n",
        "for key in histories.keys():\n",
        "  if len(histories[key]) > min_history:\n",
        "    for h in histories[key]:\n",
        "      history_x.append(h[0])\n",
        "      history_y.append(h[1])\n",
        "\n",
        "H, xedges, yedges = np.histogram2d(history_x, history_y, bins=(xedges, yedges))\n",
        "H = np.flipud(H.T)\n",
        "H"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpLV31BE9Ov5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.imshow(H, interpolation='nearest', origin='low',\n",
        "        extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4h1WenoDgZB9",
        "colab_type": "text"
      },
      "source": [
        "## Apply Trajectory Density to Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "021UicA5-SC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "background_density = background.copy()\n",
        "density_mult = 5\n",
        "darken_by = 50\n",
        "box_margin = 0\n",
        "\n",
        "H_ = H.T\n",
        "\n",
        "block_size = (40, 40)\n",
        "\n",
        "max_count = np.max(np.max(H))\n",
        "print('max count:', max_count)\n",
        "\n",
        "for i in range(x_range-1):\n",
        "  for j in range(y_range-1):\n",
        "    if H_[i,y_range-j-2] > 0:\n",
        "      background_density[(j*block_size[1]):((j+1)*block_size[1]-box_margin), (i*block_size[0]):((i+1)*block_size[0]-box_margin), :] = np.clip(np.int16(background_density[(j*block_size[1]):((j+1)*block_size[1]-box_margin), (i*block_size[0]):((i+1)*block_size[0]-box_margin), :]) + (0,0,density_mult*H_[i,y_range-j-2]*255/max_count), 0,255)\n",
        "    else:\n",
        "      background_density[(j*block_size[1]):((j+1)*block_size[1]-box_margin), (i*block_size[0]):((i+1)*block_size[0]-box_margin), :] = np.clip(np.int16(background_density[(j*block_size[1]):((j+1)*block_size[1]-box_margin), (i*block_size[0]):((i+1)*block_size[0]-box_margin), :]) - (darken_by), 0,255)\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChFR9b7Klkzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv2_imshow(background_density)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56FvOY4dKgU2",
        "colab_type": "text"
      },
      "source": [
        "## Copy the video to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vbpbWQZlsWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRgddO0qKldC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cp /content/output.mp4 /content/drive/My\\ Drive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_5IckT5NAtG",
        "colab_type": "text"
      },
      "source": [
        "## Analysis\n",
        "- People are mostly walking on the left lane and cars are using the right lane. That's the reason why trajectory density is lower on the right lane.\n",
        "\n",
        "- Small area on the lower left has low trajectory density because there is a bike and a tree. People have to walk a bit further to get onto the sidewalk.\n",
        "\n",
        "- Some people are undetected by the model. Trying different models for human detection should help this.\n",
        "\n",
        "- Some different people are tracked as the same person. More complex tracking algorithm, such as color features, should help this.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG_FU-D6L2kv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}